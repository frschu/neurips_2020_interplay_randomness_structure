{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1597323763938,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "2MXJ0aADKNRN",
    "outputId": "b5f6505f-d540-4e9b-c505-a65370f69af4"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from model_LSTM import RNN\n",
    "\n",
    "# Data directory for saving\n",
    "from data_dir import data_dir as model_dir\n",
    "# Directory for datasets and pretrained word vectors\n",
    "datasets_dir = os.path.join(model_dir, 'sentiment_analysis/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1597323763938,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "2MXJ0aADKNRN",
    "outputId": "b5f6505f-d540-4e9b-c505-a65370f69af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save model to \n",
      "  '../../../data/nlp/sentiment_analysis/saved_models\\sst_lstm_nlayers_2_nhid_256_emb_pretrained_fix_dim_100_dropout_05_weight_decay_0000_seed_4724.pt'\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "# TSM: Tai, Socher, Manning, 2015 for SST-2\n",
    "# Choose dataset\n",
    "DATASET = ['SST', 'IMDB'][0]\n",
    "# Choose pretrained embedding? (GloVe)\n",
    "PRETRAINED_EMB = True       # TSM: T\n",
    "# Scale pretrained embedding by 1/sqrt(N)\n",
    "SCALE_EMB = False\n",
    "# Train the embedding?\n",
    "TRAIN_EMB = False           # TSM: T\n",
    "\n",
    "# Data set and training parameters\n",
    "if DATASET == 'SST':\n",
    "    MAX_VOCAB_SIZE = None   # max: 15431; TSM: None\n",
    "    N_LAYERS = 2            # TSM: 1, 2\n",
    "\n",
    "    RNN_TYPE = 'LSTM'       # TSM: LSTM\n",
    "    BATCH_SIZE = 64         # TSM: 25 (paper) or 5 (github repo)\n",
    "    EMB_DIM = [50, 100, 200, 300][1] # TSM: 300\n",
    "    HIDDEN_DIM = 256       # TSM: 150\n",
    "    G_REC = None\n",
    "    N_EPOCHS = 500\n",
    "    DROPOUT = 0.5\n",
    "\n",
    "    # RNN_TYPE = 'RNN'\n",
    "    # BATCH_SIZE = 64\n",
    "    # EMB_DIM = [50, 100, 200, 300][1] \n",
    "    # HIDDEN_DIM = 1024\n",
    "    # G_REC = None\n",
    "    # N_EPOCHS = 200\n",
    "    # DROPOUT = 0.0 \n",
    "\n",
    "elif DATASET == 'IMDB':\n",
    "    MAX_VOCAB_SIZE = 25_000 # for IMDB\n",
    "    BATCH_SIZE = 64\n",
    "    HIDDEN_DIM = 1024\n",
    "    N_LAYERS = 2\n",
    "    RNN_TYPE = 'LSTM'\n",
    "    N_EPOCHS = 500\n",
    "    EMB_DIM = [50, 100, 200, 300][3]\n",
    "    G_REC = None\n",
    "    DROPOUT = 0.2           # TSM: 0.5\n",
    "# Network parameters\n",
    "BIDIRECTIONAL = False       # TSM: F, T\n",
    "WEIGHT_DECAY = 0            # TSM: 0\n",
    "\n",
    "# Initial weight statistics from previous training?\n",
    "LOAD_WB_STAT = False\n",
    "\n",
    "# Use binary or multiple labels? \n",
    "# Use multiple for SST with neutral labels or SST-5: fine-grained sentiments).\n",
    "BINARY_LABELS = True\n",
    "\n",
    "# Random seed\n",
    "SEED = random.randint(0, 9999)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "###########################################################################\n",
    "# File name for saved model (model.pt)\n",
    "if G_REC is not None:\n",
    "    g_str = ''.join(('_g_%.1f'%G_REC).split('.'))\n",
    "# Embedding\n",
    "emb_str = '_emb'\n",
    "if PRETRAINED_EMB:\n",
    "    emb_str += \"_pretrained\"\n",
    "else:\n",
    "    emb_str += \"_random\"\n",
    "if SCALE_EMB:\n",
    "    emb_str += \"_scaled\"\n",
    "if TRAIN_EMB:\n",
    "    emb_str += \"_train\"\n",
    "else:\n",
    "    emb_str += \"_fix\"\n",
    "emb_str += '_dim_%d'%EMB_DIM\n",
    "# Regularization\n",
    "dropout_str = ''.join(('_dropout_%.1f'%DROPOUT).split('.'))\n",
    "weight_decay_str = ''.join(('_weight_decay_%.3f'%WEIGHT_DECAY).split('.'))\n",
    "# Join\n",
    "model_name = (DATASET.lower() \n",
    "              + ('_nvocab_' + str(MAX_VOCAB_SIZE) \n",
    "                 if MAX_VOCAB_SIZE is not None else '')\n",
    "              + '_' + RNN_TYPE.lower()\n",
    "              + '_nlayers_%d'%N_LAYERS \n",
    "              + '_nhid_%d'%HIDDEN_DIM \n",
    "              + (g_str if G_REC is not None else '')\n",
    "              + emb_str\n",
    "              + dropout_str\n",
    "              + weight_decay_str\n",
    "              + '_seed_%d'%SEED)\n",
    "model_name += '.pt'\n",
    "SAVE = os.path.join(model_dir, model_name)\n",
    "print(\"Will save model to \\n  '%s'\" % SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6022,
     "status": "ok",
     "timestamp": 1597323775100,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "lAb4oCOsRrxx",
    "outputId": "ca2322c8-33b1-4bf8-d426-55ac402cf4a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frsch\\anaconda3\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\frsch\\anaconda3\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading trainDevTestTrees_PTB.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "datasets\\sst\\trainDevTestTrees_PTB.zip: 100%|██████████| 790k/790k [00:02<00:00, 274kB/s]  \n",
      "C:\\Users\\frsch\\anaconda3\\lib\\site-packages\\torchtext\\data\\example.py:94: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frsch\\anaconda3\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "C:\\Users\\frsch\\anaconda3\\lib\\site-packages\\torchtext\\data\\example.py:94: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training examples: 6920\n",
      "Number of validation examples: 872\n",
      "Number of testing examples: 1821\n",
      "\n",
      "Total number of words in training dataset: 138,260\n",
      "Average sentence length: 20.0 words.\n",
      "\n",
      "Example sentence (len = 39):\n",
      "The Rock is destined to be the 21st Century 's new ` ` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean - Claud Van Damme or Steven Segal .\n"
     ]
    }
   ],
   "source": [
    "# Define how the dataset is split. \n",
    "# Tokenize = act of splitting the string into discrete 'tokens'.\n",
    "# Include length for packed padded sequences\n",
    "TEXT = data.Field(tokenize ='spacy', include_lengths=True)\n",
    "if BINARY_LABELS:\n",
    "    LABEL = data.LabelField(dtype=torch.float)\n",
    "else:\n",
    "    LABEL = data.LabelField()\n",
    "\n",
    "# Load dataset (downloads first if not provided).\n",
    "if DATASET == 'SST':\n",
    "    train_data, valid_data, test_data = datasets.SST.splits(TEXT, LABEL, \n",
    "        root=datasets_dir, fine_grained=False, filter_pred=lambda ex: ex.label != 'neutral')\n",
    "elif DATASET == 'IMDB':\n",
    "    train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root=datasets_dir)\n",
    "    print('   Loading dataset complete.')\n",
    "    # Split train into train and validation set\n",
    "    train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Understand the dataset\n",
    "print(f'\\nNumber of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "\n",
    "# Total number of words in the entire dataset (counting doubles)\n",
    "n_total_words = 0\n",
    "for ex in train_data.examples:\n",
    "    n_total_words += len(ex.text)\n",
    "print(f'\\nTotal number of words in training dataset: {n_total_words:,}')\n",
    "print(\"Average sentence length: %.1f words.\" % (n_total_words / len(train_data)))\n",
    "\n",
    "# One example sentence\n",
    "ex = train_data.examples[0].text\n",
    "print(\"\\nExample sentence (len = %d):\" % len(ex))\n",
    "print(' '.join(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5023,
     "status": "ok",
     "timestamp": 1597323775103,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "9Tzs2gfLRoMm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6082,
     "status": "ok",
     "timestamp": 1597323776642,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "KQDIWM50-uOe",
    "outputId": "fe8b6ff5-e1d8-4955-d65f-f292f4c866c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399999/400000 [00:26<00:00, 15211.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full length of vocab without capping at MAX_VOCAB_SIZE: 101,626\n",
      "Unique tokens in TEXT vocabulary: 25,002\n",
      "Unique tokens in LABEL vocabulary: 2\n",
      "LABELS: defaultdict(None, {'pos': 0, 'neg': 1})\n",
      "\n",
      "First 10 words of entire vocab:\n",
      "[['the' '202928']\n",
      " [',' '192692']\n",
      " ['.' '166088']\n",
      " ['and' '109604']\n",
      " ['a' '108799']\n",
      " ['of' '100715']\n",
      " ['to' '93410']\n",
      " ['is' '76641']\n",
      " ['in' '61096']\n",
      " ['I' '54128']]\n",
      "\n",
      "Last 5 words included in the vocab:\n",
      "[['TRULY' '6']\n",
      " ['CAUSE' '6']\n",
      " ['warmer' '6']\n",
      " ['Thirty' '6']\n",
      " ['proclaiming' '6']]\n",
      "\n",
      "Last 5 words of entire vocab:\n",
      "[['straddled' '1']\n",
      " ['generated.<br' '1']\n",
      " ['/>\"Kinjite' '1']\n",
      " ['implied).<br' '1']\n",
      " ['Mechanic' '1']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fs/gpu_ml_env/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary from training data. \n",
    "# Limit the max size of vocabulary (otherwise > 100,000).\n",
    "\n",
    "# # Randomly initialized:\n",
    "if PRETRAINED_EMB:\n",
    "    # Pretrained word embeddings (~1 GB to download!)\n",
    "    TEXT.build_vocab(train_data, \n",
    "                     max_size=MAX_VOCAB_SIZE, \n",
    "                     vectors=\"glove.6B.%dd\"%EMB_DIM, \n",
    "                     vectors_cache=datasets_dir,\n",
    "                     unk_init=torch.Tensor.normal_)\n",
    "else:\n",
    "    TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# Create iterators over datasets\n",
    "# The BucketIterator will return batches with examples of similar lengths to minimize padding. \n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    device=device)\n",
    "\n",
    "# For the vocabulary, note that there are 2 extra tokens, for <unk> and <pad>.\n",
    "print(f\"Full length of vocab without capping at \"\n",
    "      + f\"MAX_VOCAB_SIZE: {len(TEXT.vocab.freqs.most_common()):,}\")\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab):,}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab):,}\")\n",
    "print(\"LABELS:\", LABEL.vocab.stoi)\n",
    "\n",
    "assert BINARY_LABELS == (len(LABEL.vocab.stoi) == 2), '\\n\\nLabels are not binary!\\n'\n",
    "\n",
    "# Print most and least common words\n",
    "n_show = 10\n",
    "print(\"\\nFirst %d words of entire vocab:\"%n_show)\n",
    "print(np.array(TEXT.vocab.freqs.most_common(n_show)))\n",
    "n_show = 5\n",
    "print(\"\\nLast %d words included in the vocab:\"%n_show)\n",
    "print(np.array(TEXT.vocab.freqs.most_common(MAX_VOCAB_SIZE)[-n_show:]))\n",
    "print(\"\\nLast %d words of entire vocab:\"%n_show)\n",
    "print(np.array(TEXT.vocab.freqs.most_common()[-n_show:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5837,
     "status": "ok",
     "timestamp": 1597323776643,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "Vye2ZWQWXbe5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5479,
     "status": "ok",
     "timestamp": 1597323776644,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "uT-S2nsb-uOq",
    "outputId": "a4cb1dc1-e9ba-4120-d734-25395aedecd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model has 13,829,121 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# Create RNN instance\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "if BINARY_LABELS:\n",
    "    OUTPUT_DIM = 1\n",
    "else:\n",
    "    OUTPUT_DIM = len(LABEL.vocab)\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# Instantiate\n",
    "model = RNN(RNN_TYPE, INPUT_DIM, EMB_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, \n",
    "            BIDIRECTIONAL, DROPOUT, PAD_IDX, TRAIN_EMB)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'\\nThe model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "# Embedding\n",
    "if PRETRAINED_EMB:\n",
    "    # Apply pretrained embeddings\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "    model.encoder.weight.data.copy_(pretrained_embeddings)\n",
    "if SCALE_EMB:\n",
    "    model.encoder.weight.data *= 1 / np.sqrt(HIDDEN_DIM)\n",
    "# Initialize <unk> and <pad> to zero:\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "model.encoder.weight.data[UNK_IDX] = torch.zeros(EMB_DIM)\n",
    "model.encoder.weight.data[PAD_IDX] = torch.zeros(EMB_DIM)\n",
    "# print(model.embedding.weight.data)\n",
    "\n",
    "# RNN and decoder\n",
    "if LOAD_WB_STAT:\n",
    "    # Choose file\n",
    "    wb_stat_name = 'sst_emb_pretrained_scaled_fix_dim_300_lstm_nlayers_1_nhid_150_dropout_05_seed_1234'\n",
    "    # Load and set weights\n",
    "    wb_stat_file = os.path.join(model_dir, wb_stat_name)\n",
    "    with open(args.wb_stat_file, 'rb') as f:\n",
    "        wb_stat = pickle.load(f)  \n",
    "    for key, param in model.named_parameters():\n",
    "        if 'encoder' in key:\n",
    "            # Leave as is!\n",
    "            pass \n",
    "        elif 'rnn' in key:\n",
    "            # RNN weights and biases come in blocks of n_rnn * N x N. Separate these blocks.\n",
    "            for k, key_rnn in enumerate(model.keys_rnn):\n",
    "                wb_mean, wb_std = wb_stat[key][key_rnn]\n",
    "                mul = param.shape[0] // model.n_rnn\n",
    "                sub_w = param[k*mul : (k+1)*mul]\n",
    "                sub_w.data.normal_(wb_mean, wb_std)\n",
    "                print(key, key_rnn, ' ', wb_mean, wb_std)\n",
    "        elif 'decoder' in key:\n",
    "            wb_mean, wb_std = wb_stat[key]\n",
    "            param.data.normal_(wb_mean, wb_std)\n",
    "            print(key, ' ', wb_mean, wb_std)\n",
    "elif G_REC is not None:\n",
    "    # Recurrent weights\n",
    "    for key, param in model.rnn.named_parameters():\n",
    "        if 'weight' in key:\n",
    "            # Input vs. recurrent\n",
    "            hh_or_ih, layer_str = key.split('_')[1:]\n",
    "            layer = int(layer_str[1:])\n",
    "            # Input layer: scale by 1/sqrt(embedding_dim)\n",
    "            print(hh_or_ih, layer)\n",
    "            if hh_or_ih == 'ih' and layer == 0:\n",
    "                param.data.normal_(0, 1. / np.sqrt(model.embedding_dim))\n",
    "            else:\n",
    "                # LSTM and GRU cells have combined weights for the effect of the\n",
    "                # last hidden state on the new state and the gates. \n",
    "                # We scale only the hidden-to-hidden weights ('hh') by\n",
    "                # a factor g controlling the radius of the spectrum.\n",
    "                for k, key_rnn in enumerate(model.keys_rnn):\n",
    "                    mul = param.shape[0] // model.n_states\n",
    "                    sub_w = param[k*mul : (k+1)*mul]\n",
    "                    if hh_or_ih == 'hh' and key_rnn == 'c':\n",
    "                        # Scale only the recurrent state weights by g\n",
    "                        sub_w.data.normal_(0, G_REC / np.sqrt(model.hidden_dim))\n",
    "                    else:\n",
    "                        sub_w.data.normal_(0, 1. / np.sqrt(model.hidden_dim))\n",
    "        else:\n",
    "            # Biases are set to zero by default. \n",
    "            pass\n",
    "            \n",
    "        # # Decoder: leave as is...\n",
    "        # decoder_max = math.sqrt(3 / model.hidden_dim)\n",
    "        # model.decoder.weight.data.uniform_(-decoder_max, decoder_max)\n",
    "        # model.decoder.bias.data.zero_()\n",
    "else:\n",
    "    # Use standard initialization, but rescale the input weights of layer 0. \n",
    "    # model.rnn.weight_ih_l0.data.uniform_(0, 1. / np.sqrt(model.embedding_dim))\n",
    "    a = 1. / np.sqrt(model.embedding_dim)\n",
    "    model.rnn.weight_ih_l0.data.uniform_(-a, a)\n",
    "\n",
    "# Save the initial model connectivity\n",
    "state_dict_init = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# Move model to GPU before choosing the optimizer\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5245,
     "status": "ok",
     "timestamp": 1597323776644,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "j4PjVbDGCXlv"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Choose optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "# optimizer = optim.Adagrad(model.parameters(), lr=0.05)\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Learning rate for adam should be scaled by network size!\n",
    "lr0 = 0.01\n",
    "lr = lr0 / HIDDEN_DIM\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "if BINARY_LABELS:\n",
    "    # Binary cross-entropy loss with logits\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    # Binary accuracy\n",
    "    def accuracy(preds, y):\n",
    "        #round predictions to the closest integer\n",
    "        rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "        correct = (rounded_preds == y).float() #convert into float for division \n",
    "        acc = correct.sum() / len(correct)\n",
    "        return acc\n",
    "else:\n",
    "    # Cross-entropy loss\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # Categorical accuracy\n",
    "    def accuracy(preds, y):\n",
    "        \"\"\" Categorical accuracy for multiple classes.\"\"\"\n",
    "        max_preds = preds.argmax(dim=1, keepdim=True) # get the index of the max probability\n",
    "        correct = max_preds.squeeze(1).eq(y)\n",
    "        return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "id": "RB39dWFDT4L_",
    "outputId": "e1316be3-8a53-45dc-e51b-2a82e50d415d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fs/gpu_ml_env/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 4s\n",
      "\tTrain Loss: 0.693 | Train Acc: 50.73%\n",
      "\t Val. Loss: 0.693 |  Val. Acc: 49.30%\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "best_valid_loss = float('inf')\n",
    "train_losses, valid_losses = np.zeros((2, N_EPOCHS))\n",
    "loss_acc = np.zeros((N_EPOCHS, 4))\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # Save losses and accuracy\n",
    "    loss_acc[epoch] = train_loss, valid_loss, train_acc, valid_acc\n",
    "\n",
    "    # # Save the best model so far\n",
    "    # if valid_loss < best_valid_loss:\n",
    "    #     best_valid_loss = valid_loss\n",
    "    #     state_dict_best = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    show_step = N_EPOCHS // 20\n",
    "    if (epoch + 1) % show_step == 0 or epoch == 0:\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        # Save\n",
    "        state_dict_final = model.state_dict()\n",
    "        with open(SAVE, 'wb') as f:\n",
    "            torch.save({'state_dict_init': state_dict_init,\n",
    "                        'state_dict_final': state_dict_final,\n",
    "                        'loss_acc': loss_acc,\n",
    "                        }, f)\n",
    "\n",
    "\n",
    "#######################################################################        \n",
    "# Save the initial and last model\n",
    "state_dict_final = model.state_dict()\n",
    "with open(SAVE, 'wb') as f:\n",
    "    torch.save({'state_dict_init': state_dict_init,\n",
    "                'state_dict_final': state_dict_final,\n",
    "                'loss_acc': loss_acc,\n",
    "                }, f)\n",
    "# print(\"Saved last model to '%s'\" % SAVE)\n",
    "print(\"Saved initial and final model to '%s'\" % SAVE)\n",
    "# print(\"Saved best model to '%s'\" % SAVE)\n",
    "\n",
    "# Save the initial and last model\n",
    "state_dict_final = model.state_dict()\n",
    "with open(SAVE, 'wb') as f:\n",
    "    torch.save({'state_dict_init': state_dict_init,\n",
    "                'state_dict_final': state_dict_final,\n",
    "                'loss_acc': loss_acc,\n",
    "                }, f)\n",
    "# print(\"Saved last model to '%s'\" % SAVE)\n",
    "print(\"Saved initial and final model to '%s'\" % SAVE)\n",
    "\n",
    "# Plot loss and accuracy over training epochs\n",
    "fig = plt.figure(figsize=(6, 6), facecolor='w')\n",
    "axes = fig.subplots(2, 1)\n",
    "axes = axes[:, None]\n",
    "epochs = np.arange(N_EPOCHS)\n",
    "train_loss, valid_loss, train_acc, valid_acc = loss_acc.T\n",
    "ax = axes[0, 0]\n",
    "ax.plot(epochs, train_loss, label='train')\n",
    "ax.plot(epochs, valid_loss, label='valid')\n",
    "ax.axhline(0, c='0.5', zorder=-1)\n",
    "ax.legend()\n",
    "ax.set_ylabel('Loss')\n",
    "ax = axes[1, 0]\n",
    "ax.plot(epochs, train_acc, label='train')\n",
    "ax.plot(epochs, valid_acc, label='valid')\n",
    "ax.axhline(0, c='0.5', zorder=-1)\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nN4y_EfmUSqk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FSmXtxwgGnO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKX2UIA8Ll0B"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Evaluate truncated networks\n",
    "max_rank = HIDDEN_DIM\n",
    "# rank_step = HIDDEN_DIM // 128\n",
    "rank_step = 1\n",
    "trunc_ranks = np.arange(0, max_rank, rank_step)\n",
    "n_rank = len(trunc_ranks)\n",
    "\n",
    "# Keys\n",
    "keys_rnn = model.keys_rnn\n",
    "n_states = len(keys_rnn)\n",
    "nhid = HIDDEN_DIM \n",
    "\n",
    "svd_blockwise = False\n",
    "\n",
    "############################################################################\n",
    "trunc_loss_acc = np.zeros((2, n_rank, 2))\n",
    "\n",
    "time0 = time.time()\n",
    "for j in range(2):\n",
    "    trunc_dw = j == 0\n",
    "    for i, rank in enumerate(trunc_ranks):\n",
    "        print(j, i, rank)\n",
    "\n",
    "        # Weights and biases for truncated model\n",
    "        state_dict_trunc = OrderedDict()\n",
    "        \n",
    "        # Weights\n",
    "        for key in state_dict_final.keys():\n",
    "            # Truncate only 'inner' weights with NxN\n",
    "            cond_trunc = (\n",
    "                ('rnn.weight' in key) \n",
    "                * (('hh' in key) or ('ih' in key))\n",
    "                * (not 'ih_l0' in key))\n",
    "            if cond_trunc:\n",
    "                # print(\"Truncate\", key)\n",
    "                if svd_blockwise:\n",
    "                    # LSTM and GRU cells have combined weights for the effect of the\n",
    "                    # last hidden state on the new state and the gates. \n",
    "                    w_trunc_rnn = np.zeros((n_states * nhid, nhid))\n",
    "                    for k, key_rnn in enumerate(keys_rnn):\n",
    "                        # Get weights\n",
    "                        w = state_dict_final[key][k*nhid : (k+1)*nhid]\n",
    "                        # Move to cpu\n",
    "                        w = w.cpu()\n",
    "                        if trunc_dw:\n",
    "                            # Obtain changes\n",
    "                            w0 = state_dict_init[key][k*nhid : (k+1)*nhid]\n",
    "                            w0 = w0.cpu()\n",
    "                            dw = w - w0\n",
    "                            # Truncate dw at given rank:\n",
    "                            u, s, vT = np.linalg.svd(dw, full_matrices=False)\n",
    "                            dw_trunc = (u[:, :rank] * s[None, :rank]) @ vT[:rank]\n",
    "                            # Unite with initial connecitivity\n",
    "                            w_trunc_rnn[k*nhid : (k+1)*nhid] = w0 + dw_trunc\n",
    "                        else:\n",
    "                            # Truncate w at given rank:\n",
    "                            u, s, vT = np.linalg.svd(w, full_matrices=False)\n",
    "                            w_trunc = (u[:, :rank] * s[None, :rank]) @ vT[:rank]\n",
    "                            w_trunc_rnn[k*nhid : (k+1)*nhid] = w_trunc\n",
    "                    # Add to state dict\n",
    "                    w_trunc_rnn = torch.from_numpy(w_trunc_rnn).cuda()\n",
    "                    state_dict_trunc[key] = w_trunc_rnn\n",
    "                else:\n",
    "                    # Get weights\n",
    "                    w = state_dict_final[key]\n",
    "                    # Move to cpu\n",
    "                    w = w.cpu()\n",
    "                    if trunc_dw:\n",
    "                        # Obtain changes\n",
    "                        w0 = state_dict_init[key]\n",
    "                        w0 = w0.cpu()\n",
    "                        dw = w - w0\n",
    "                        # Truncate dw at given rank:\n",
    "                        u, s, vT = np.linalg.svd(dw, full_matrices=False)\n",
    "                        dw_trunc = (u[:, :rank] * s[None, :rank]) @ vT[:rank]\n",
    "                        # Unite with initial connecitivity\n",
    "                        w_trunc_rnn = w0.numpy() + dw_trunc\n",
    "                    else:\n",
    "                        # Truncate w at given rank:\n",
    "                        u, s, vT = np.linalg.svd(w, full_matrices=False)\n",
    "                        w_trunc = (u[:, :rank] * s[None, :rank]) @ vT[:rank]\n",
    "                        w_trunc_rnn = w_trunc\n",
    "                # Add to state dict\n",
    "                w_trunc_rnn = torch.from_numpy(w_trunc_rnn).cuda()\n",
    "                state_dict_trunc[key] = w_trunc_rnn\n",
    "            else:\n",
    "                # print(\"Leave\", key)\n",
    "                state_dict_trunc[key] = copy.deepcopy(state_dict_final[key])\n",
    "        \n",
    "        # Define truncated model\n",
    "        model_trunc = RNN(RNN_TYPE, INPUT_DIM, EMB_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
    "                          N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX, TRAIN_EMB)\n",
    "        model_trunc.load_state_dict(state_dict_trunc)\n",
    "        # Evaluate\n",
    "        model_trunc.to(device)\n",
    "        trunc_loss_acc[j, i] = evaluate(model_trunc, valid_iterator, criterion)\n",
    "        del model_trunc\n",
    "print('Computing truncation loss took %.1f sec.' % (time.time() - time0))\n",
    "\n",
    "\n",
    "# Save everything\n",
    "state_dict_final = model.state_dict()\n",
    "with open(SAVE, 'wb') as f:\n",
    "    torch.save({'state_dict_init': state_dict_init,\n",
    "                'state_dict_final': state_dict_final,\n",
    "                'loss_acc': loss_acc,\n",
    "                'trunc_loss_acc': trunc_loss_acc,\n",
    "                'trunc_ranks': trunc_ranks,\n",
    "                'svd_blockwise': svd_blockwise,\n",
    "                }, f)\n",
    "# print(\"Saved last model to '%s'\" % SAVE)\n",
    "print(\"Saved initial and final model to '%s'\" % SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-wfE8bTaidk"
   },
   "outputs": [],
   "source": [
    "# Plot loss and accuracy over training epochs\n",
    "fig = plt.figure(figsize=(6, 6), facecolor='w')\n",
    "axes = fig.subplots(2, 1, sharex=True)\n",
    "axes = axes[:, None]\n",
    "epochs = np.arange(N_EPOCHS)\n",
    "train_loss, valid_loss, train_acc, valid_acc = loss_acc.T\n",
    "\n",
    "ax0, ax1 = axes[:, 0]\n",
    "\n",
    "for j in range(2):\n",
    "    # ls = ['-', '--'][j]\n",
    "    ls = '-'\n",
    "    lbl = ['Truncate dw', 'Truncate w'][j]\n",
    "    c = ['0.3', '0.8'][j]\n",
    "\n",
    "    trunc_loss, trunc_acc = trunc_loss_acc[j].T\n",
    "    ax0.plot(trunc_ranks, trunc_loss, ls, c=c, label=lbl)\n",
    "    ax1.plot(trunc_ranks, trunc_acc, ls, c=c, label=lbl)\n",
    "\n",
    "# Initial and final loss and accuracy\n",
    "c = '0.5'\n",
    "ax0.axhline(valid_loss[0], ls='--', c=c, label='Initial')\n",
    "ax1.axhline(valid_acc[0], ls=':', c=c, label='Initial')\n",
    "ax0.axhline(valid_loss[-1], ls='--', c=c, label='Final')\n",
    "ax1.axhline(valid_acc[-1], ls=':', c=c, label='Final')\n",
    "\n",
    "ax0.legend()\n",
    "# ax0.axhline(0, c='0.5', zorder=-1)\n",
    "# ax1.axhline(0, c='0.5', zorder=-1)\n",
    "ax0.set_ylabel('Loss')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel(\"Truncation rank\")\n",
    "\n",
    "plt.show(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXzD-MitVstx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRmNEmztakGp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFeWrLUrakJk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaCYSvajakMx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjcH1W1HakPj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f0TyyDQXakeQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZGCWFjCakhG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11915,
     "status": "ok",
     "timestamp": 1597315287705,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "wOhQOEhgVsw6",
    "outputId": "5a8811da-42f1-4bd3-ed13-50430c6a31ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not defined\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "SAVE = 'saved_models/sst_lstm_nlayers_1_nhid_1024_emb_pretrained_fix_dim_100_dropout_00_weight_decay_0000_seed_4375.pt'\n",
    "\n",
    "data_file = SAVE\n",
    "with open(data_file, 'rb') as f:\n",
    "    res = torch.load(f, map_location=torch.device(device))\n",
    "    state_dict_init = res['state_dict_init']\n",
    "    state_dict_final = res['state_dict_final']\n",
    "    loss_acc = res['loss_acc']\n",
    "    try:\n",
    "        trunc_loss_acc = res['trunc_loss_acc']\n",
    "        trunc_ranks = res['trunc_ranks']\n",
    "    except:\n",
    "        print('not defined')\n",
    "\n",
    "train_loss, valid_loss, train_acc, valid_acc = loss_acc.T\n",
    "N_EPOCHS = len(train_loss)\n",
    "\n",
    "# Obtain dimensions\n",
    "INPUT_DIM, EMB_DIM = state_dict_init[\"encoder.weight\"].shape\n",
    "OUTPUT_DIM, HIDDEN_DIM = state_dict_init[\"decoder.weight\"].shape\n",
    "N_LAYERS = max([int(key[-1])  \n",
    "                for key in state_dict_init.keys() \n",
    "                if key[-3:-1] == '_l']) + 1\n",
    "BIDIRECTIONAL = False\n",
    "DROPOUT = 0\n",
    "try:\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "except:\n",
    "    PAD_IDX = 1\n",
    "\n",
    "# Instantiate\n",
    "model = RNN(RNN_TYPE, INPUT_DIM, EMB_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, \n",
    "            BIDIRECTIONAL, DROPOUT, PAD_IDX, TRAIN_EMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1597315290569,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "nsoE8DO6Vs2X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1597315290573,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "4XYr1tDIZn38"
   },
   "outputs": [],
   "source": [
    "\n",
    "if BINARY_LABELS:\n",
    "    # Binary cross-entropy loss with logits\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    # Binary accuracy\n",
    "    def accuracy(preds, y):\n",
    "        #round predictions to the closest integer\n",
    "        rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "        correct = (rounded_preds == y).float() #convert into float for division \n",
    "        acc = correct.sum() / len(correct)\n",
    "        return acc\n",
    "else:\n",
    "    # Cross-entropy loss\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # Categorical accuracy\n",
    "    def accuracy(preds, y):\n",
    "        \"\"\" Categorical accuracy for multiple classes.\"\"\"\n",
    "        max_preds = preds.argmax(dim=1, keepdim=True) # get the index of the max probability\n",
    "        correct = max_preds.squeeze(1).eq(y)\n",
    "        return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
    "        \n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 344083,
     "status": "ok",
     "timestamp": 1597316421326,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "9AGbY9o-3lk1",
    "outputId": "95f34b26-7ad3-42b0-bfa0-fbd8ed1952f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 16\n",
      "0 2 32\n",
      "0 3 48\n",
      "0 4 64\n",
      "0 5 80\n",
      "0 6 96\n",
      "0 7 112\n",
      "0 8 128\n",
      "0 9 144\n",
      "0 10 160\n",
      "0 11 176\n",
      "0 12 192\n",
      "0 13 208\n",
      "0 14 224\n",
      "0 15 240\n",
      "0 16 256\n",
      "0 17 272\n",
      "0 18 288\n",
      "0 19 304\n",
      "0 20 320\n",
      "0 21 336\n",
      "0 22 352\n",
      "0 23 368\n",
      "0 24 384\n",
      "0 25 400\n",
      "0 26 416\n",
      "0 27 432\n",
      "0 28 448\n",
      "0 29 464\n",
      "0 30 480\n",
      "0 31 496\n",
      "0 32 512\n",
      "0 33 528\n",
      "0 34 544\n",
      "0 35 560\n",
      "0 36 576\n",
      "0 37 592\n",
      "0 38 608\n",
      "0 39 624\n",
      "0 40 640\n",
      "0 41 656\n",
      "0 42 672\n",
      "0 43 688\n",
      "0 44 704\n",
      "0 45 720\n",
      "0 46 736\n",
      "0 47 752\n",
      "0 48 768\n",
      "0 49 784\n",
      "0 50 800\n",
      "0 51 816\n",
      "0 52 832\n",
      "0 53 848\n",
      "0 54 864\n",
      "0 55 880\n",
      "0 56 896\n",
      "0 57 912\n",
      "0 58 928\n",
      "0 59 944\n",
      "0 60 960\n",
      "0 61 976\n",
      "0 62 992\n",
      "0 63 1008\n",
      "1 0 0\n",
      "1 1 16\n",
      "1 2 32\n",
      "1 3 48\n",
      "1 4 64\n",
      "1 5 80\n",
      "1 6 96\n",
      "1 7 112\n",
      "1 8 128\n",
      "1 9 144\n",
      "1 10 160\n",
      "1 11 176\n",
      "1 12 192\n",
      "1 13 208\n",
      "1 14 224\n",
      "1 15 240\n",
      "1 16 256\n",
      "1 17 272\n",
      "1 18 288\n",
      "1 19 304\n",
      "1 20 320\n",
      "1 21 336\n",
      "1 22 352\n",
      "1 23 368\n",
      "1 24 384\n",
      "1 25 400\n",
      "1 26 416\n",
      "1 27 432\n",
      "1 28 448\n",
      "1 29 464\n",
      "1 30 480\n",
      "1 31 496\n",
      "1 32 512\n",
      "1 33 528\n",
      "1 34 544\n",
      "1 35 560\n",
      "1 36 576\n",
      "1 37 592\n",
      "1 38 608\n",
      "1 39 624\n",
      "1 40 640\n",
      "1 41 656\n",
      "1 42 672\n",
      "1 43 688\n",
      "1 44 704\n",
      "1 45 720\n",
      "1 46 736\n",
      "1 47 752\n",
      "1 48 768\n",
      "1 49 784\n",
      "1 50 800\n",
      "1 51 816\n",
      "1 52 832\n",
      "1 53 848\n",
      "1 54 864\n",
      "1 55 880\n",
      "1 56 896\n",
      "1 57 912\n",
      "1 58 928\n",
      "1 59 944\n",
      "1 60 960\n",
      "1 61 976\n",
      "1 62 992\n",
      "1 63 1008\n",
      "Computing truncation loss took 343.4 sec.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Evaluate truncated networks\n",
    "max_rank = HIDDEN_DIM\n",
    "rank_step = HIDDEN_DIM // 64\n",
    "trunc_ranks = np.arange(0, max_rank, rank_step)\n",
    "n_rank = len(trunc_ranks)\n",
    "\n",
    "# Keys\n",
    "keys_rnn = model.keys_rnn\n",
    "n_states = len(keys_rnn)\n",
    "nhid = HIDDEN_DIM \n",
    "\n",
    "svd_blockwise = False\n",
    "\n",
    "############################################################################\n",
    "trunc_loss_acc = np.zeros((2, n_rank, 2))\n",
    "\n",
    "time0 = time.time()\n",
    "for j in range(2):\n",
    "    trunc_dw = j == 0\n",
    "    for i, rank in enumerate(trunc_ranks):\n",
    "        print(j, i, rank)\n",
    "\n",
    "        # Weights and biases for truncated model\n",
    "        state_dict_trunc = OrderedDict()\n",
    "        \n",
    "        # Weights\n",
    "        for key in state_dict_final.keys():\n",
    "            # Truncate only 'inner' weights with NxN\n",
    "            cond_trunc = (\n",
    "                ('rnn.weight' in key) \n",
    "                * (('hh' in key) or ('ih' in key))\n",
    "                * (not 'ih_l0' in key))\n",
    "            if cond_trunc:\n",
    "                # print(\"Truncate\", key)\n",
    "                if svd_blockwise:\n",
    "                    # LSTM and GRU cells have combined weights for the effect of the\n",
    "                    # last hidden state on the new state and the gates. \n",
    "                    w_trunc_rnn = np.zeros((n_states * nhid, nhid))\n",
    "                    for k, key_rnn in enumerate(keys_rnn):\n",
    "                        # Get weights\n",
    "                        w = state_dict_final[key][k*nhid : (k+1)*nhid]\n",
    "                        # Move to cpu\n",
    "                        w = w.cpu()\n",
    "                        if trunc_dw:\n",
    "                            # Obtain changes\n",
    "                            w0 = state_dict_init[key][k*nhid : (k+1)*nhid]\n",
    "                            w0 = w0.cpu()\n",
    "                            dw = w - w0\n",
    "                            # Truncate dw at given rank:\n",
    "                            u, s, vT = np.linalg.svd(dw, full_matrices=False)\n",
    "                            dw_trunc = (u[:, :rank] * s[None, :rank]) @ vT[:rank]\n",
    "                            # Unite with initial connecitivity\n",
    "                            w_trunc_rnn[k*nhid : (k+1)*nhid] = w0 + dw_trunc\n",
    "                        else:\n",
    "                            # Truncate w at given rank:\n",
    "                            u, s, vT = np.linalg.svd(w, full_matrices=False)\n",
    "                            w_trunc = (u[:, :rank] * s[None, :rank]) @ vT[:rank]\n",
    "                            w_trunc_rnn[k*nhid : (k+1)*nhid] = w_trunc\n",
    "                    # Add to state dict\n",
    "                    w_trunc_rnn = torch.from_numpy(w_trunc_rnn).cuda()\n",
    "                    state_dict_trunc[key] = w_trunc_rnn\n",
    "                else:\n",
    "                    # Get weights\n",
    "                    w = state_dict_final[key]\n",
    "                    # Move to cpu\n",
    "                    w = w.cpu()\n",
    "                    if trunc_dw:\n",
    "                        # Obtain changes\n",
    "                        w0 = state_dict_init[key]\n",
    "                        w0 = w0.cpu()\n",
    "                        dw = w - w0\n",
    "                        # Truncate dw at given rank:\n",
    "                        u, s, vT = np.linalg.svd(dw, full_matrices=False)\n",
    "                        dw_trunc = (u[:, :rank] * s[None, :rank]) @ vT[:rank]\n",
    "                        # Unite with initial connecitivity\n",
    "                        w_trunc_rnn = w0.numpy() + dw_trunc\n",
    "                    else:\n",
    "                        # Truncate w at given rank:\n",
    "                        u, s, vT = np.linalg.svd(w, full_matrices=False)\n",
    "                        w_trunc = (u[:, :rank] * s[None, :rank]) @ vT[:rank]\n",
    "                        w_trunc_rnn = w_trunc\n",
    "                # Add to state dict\n",
    "                w_trunc_rnn = torch.from_numpy(w_trunc_rnn).cuda()\n",
    "                state_dict_trunc[key] = w_trunc_rnn\n",
    "            else:\n",
    "                # print(\"Leave\", key)\n",
    "                state_dict_trunc[key] = copy.deepcopy(state_dict_final[key])\n",
    "        \n",
    "        # Define truncated model\n",
    "        model_trunc = RNN(RNN_TYPE, INPUT_DIM, EMB_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
    "                          N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX, TRAIN_EMB)\n",
    "        model_trunc.load_state_dict(state_dict_trunc)\n",
    "        # Evaluate\n",
    "        model_trunc.to(device)\n",
    "        trunc_loss_acc[j, i] = evaluate(model_trunc, valid_iterator, criterion)\n",
    "        del model_trunc\n",
    "print('Computing truncation loss took %.1f sec.' % (time.time() - time0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1597315008133,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "dIjsTeMrZKM8",
    "outputId": "fc10af5a-aa35-4642-f7f0-0b5bab66d4f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1152,
     "status": "ok",
     "timestamp": 1597316483472,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "H1zzbRpMxwU2",
    "outputId": "7902c5e8-3f7b-4c91-e33c-8803d16468be"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss and accuracy over training epochs\n",
    "fig = plt.figure(figsize=(6, 6), facecolor='w')\n",
    "axes = fig.subplots(2, 1, sharex=True)\n",
    "axes = axes[:, None]\n",
    "epochs = np.arange(N_EPOCHS)\n",
    "train_loss, valid_loss, train_acc, valid_acc = loss_acc.T\n",
    "\n",
    "ax0, ax1 = axes[:, 0]\n",
    "\n",
    "for j in range(2):\n",
    "    # ls = ['-', '--'][j]\n",
    "    ls = '-'\n",
    "    lbl = ['Truncate dw', 'Truncate w'][j]\n",
    "    # c = colors[0]\n",
    "    c = ['0.3', '0.8'][j]\n",
    "\n",
    "    trunc_loss, trunc_acc = trunc_loss_acc[j].T\n",
    "    ax0.plot(trunc_ranks, trunc_loss, ls, c=c, label=lbl)\n",
    "    ax1.plot(trunc_ranks, trunc_acc, ls, c=c, label=lbl)\n",
    "\n",
    "# Initial and final loss and accuracy\n",
    "c = '0.5'\n",
    "ax0.axhline(valid_loss[0], ls='--', c=c, label='Initial')\n",
    "ax1.axhline(valid_acc[0], ls=':', c=c, label='Initial')\n",
    "ax0.axhline(valid_loss[-1], ls='--', c=c, label='Final')\n",
    "ax1.axhline(valid_acc[-1], ls=':', c=c, label='Final')\n",
    "\n",
    "ax0.legend()\n",
    "# ax0.axhline(0, c='0.5', zorder=-1)\n",
    "# ax1.axhline(0, c='0.5', zorder=-1)\n",
    "ax0.set_ylabel('Loss')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel(\"Truncation rank\")\n",
    "\n",
    "plt.show(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1597316497776,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "lXlfX_01LggQ",
    "outputId": "99c04279-9bdb-49d8-d92c-969532748c3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved initial and final model to 'saved_models/sst_lstm_nlayers_1_nhid_1024_emb_pretrained_fix_dim_100_dropout_00_weight_decay_0000_seed_4375.pt'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Save everything\n",
    "state_dict_final = model.state_dict()\n",
    "with open(SAVE, 'wb') as f:\n",
    "    torch.save({'state_dict_init': state_dict_init,\n",
    "                'state_dict_final': state_dict_final,\n",
    "                'loss_acc': loss_acc,\n",
    "                'trunc_loss_acc': trunc_loss_acc,\n",
    "                'trunc_ranks': trunc_ranks,\n",
    "                'svd_blockwise': svd_blockwise,\n",
    "                }, f)\n",
    "# print(\"Saved last model to '%s'\" % SAVE)\n",
    "print(\"Saved initial and final model to '%s'\" % SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 501275,
     "status": "ok",
     "timestamp": 1597259520916,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "r3SQVwED-uO0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 97039,
     "status": "ok",
     "timestamp": 1597253655977,
     "user": {
      "displayName": "Fr Schu",
      "photoUrl": "",
      "userId": "09731992798374122010"
     },
     "user_tz": -180
    },
    "id": "55LexzG_-uO5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lnl1V2-D-uO-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
