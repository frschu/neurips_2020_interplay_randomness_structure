{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from helpers import comp_evs\n",
    "\n",
    "# RNN model and task\n",
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "from model import RNN, train, run_net\n",
    "from task_generators import flipflop, mante, romo\n",
    "\n",
    "# Data directory for saving\n",
    "from data_dir import data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Shared parameters\n",
    "# optimizer = 'sgd'\n",
    "optimizer = 'adam'\n",
    "# Integration time step\n",
    "dt = 0.5\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "batch_size_test = 512\n",
    "# Neural noise\n",
    "noise_std = 0.\n",
    "# Whether IO vectors are orthogonalized\n",
    "orthogonalize_wio = False\n",
    "# Same random connectivity for each g?\n",
    "same_connectivity = False\n",
    "# Reconstruction loss\n",
    "n_ranks = 26\n",
    "\n",
    "# Network architecture\n",
    "ML_RNN = False\n",
    "nonlinearity = 'tanh'\n",
    "readout_nonlinearity = None\n",
    "\n",
    "# Task names\n",
    "tasks_file_name_prefix = [\"flipflop\", \"mante\", \"romo\"]\n",
    "# Number of epochs\n",
    "tasks_n_epochs = np.array([1000, 2000, 6000])\n",
    "# Number of kept weight matrices (we don't really need this for the analysis...)\n",
    "n_rec_epochs = 200\n",
    "\n",
    "# Learning rate\n",
    "lr0 = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over network size\n",
    "dim_recs = np.array([64, 128, 256, 512, 1024])\n",
    "\n",
    "# Simulate and analyze all three tasks for multiple samples. \n",
    "n_samples = 5\n",
    "\n",
    "# Values for g\n",
    "tasks_gs = np.array([[0., 0.9, 1.8]]*3)\n",
    "\n",
    "dim_recs = np.array([32])\n",
    "n_samples = 1\n",
    "tasks_gs = np.array([[0.9]]*3)\n",
    "\n",
    "# What to train\n",
    "train_wi=True\n",
    "train_wrec=True\n",
    "train_wo=True\n",
    "train_brec=False\n",
    "\n",
    "# Task names\n",
    "tasks_file_name_prefix = [\"flipflop\", \"mante\", \"romo\"]\n",
    "tasks_file_name_prefix = [fn + \"_dim_recs\" for fn in tasks_file_name_prefix ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(task_specs):\n",
    "    (file_name_prefix, n_epochs, gs, dims, task_params, task_generator\n",
    "    ) = task_specs\n",
    "    # Task\n",
    "    task = task_generator(dims, dt, **task_params)\n",
    "    n_gs = len(gs)\n",
    "    dim_in, dim_rec, dim_out = dims\n",
    "    \n",
    "    # Epochs\n",
    "    rec_step = n_epochs // n_rec_epochs\n",
    "    epochs = np.arange(n_epochs)\n",
    "    rec_epochs = np.arange(0, n_epochs, rec_step)\n",
    "    \n",
    "    # Learning rate\n",
    "    if optimizer == 'sgd':\n",
    "        lr = lr0\n",
    "    elif optimizer == 'adam':\n",
    "        lr = lr0 / dim_rec\n",
    "    \n",
    "    # For rank truncation\n",
    "    ranks = np.arange(n_ranks) \n",
    "    rank_max = ranks[-1] + 1\n",
    "    \n",
    "    # Weights\n",
    "    wi_init_all = np.zeros((n_samples, n_gs, dim_in, dim_rec))\n",
    "    wrec_init_all = np.zeros((n_samples, n_gs, dim_rec, dim_rec))\n",
    "    wo_init_all = np.zeros((n_samples, n_gs, dim_rec, dim_out))\n",
    "    brec_init_all = np.zeros((n_samples, n_gs, dim_rec))\n",
    "    wi_last_all = np.zeros((n_samples, n_gs, dim_in, dim_rec))\n",
    "    wrec_last_all = np.zeros((n_samples, n_gs, dim_rec, dim_rec))\n",
    "    wo_last_all = np.zeros((n_samples, n_gs, dim_rec, dim_out))\n",
    "    brec_last_all = np.zeros((n_samples, n_gs, dim_rec))\n",
    "    if train_wi:\n",
    "        wis_all = np.zeros((n_samples, n_gs, n_rec_epochs, dim_in, dim_rec))\n",
    "    if train_wo:\n",
    "        wos_all = np.zeros((n_samples, n_gs, n_rec_epochs, dim_rec, dim_out))\n",
    "    if train_brec:\n",
    "        brecs_all = np.zeros((n_samples, n_gs, n_rec_epochs, dim_rec))\n",
    "    # Results\n",
    "    losses_all = np.zeros((n_samples, n_gs, n_epochs))\n",
    "    grad_norms_all = np.zeros((n_samples, n_gs, n_epochs))\n",
    "    sv_dw_all = np.zeros((n_samples, n_gs, n_rec_epochs, dim_rec))\n",
    "    loss_rr_all = np.zeros((n_samples, n_gs, n_ranks))\n",
    "    norm_diff_rr_all = np.zeros((n_samples, n_gs, n_ranks))\n",
    "    var_expl_all = np.zeros((n_samples, n_gs, n_ranks))\n",
    "    loss_shuff_all = np.zeros((n_samples, n_gs))\n",
    "    ev_all = np.zeros((3, n_samples, n_gs, dim_rec), dtype=complex)\n",
    "    sv_all = np.zeros((3, n_samples, n_gs, dim_rec))\n",
    "\n",
    "    # Figure and file name\n",
    "    file_name = file_name_prefix\n",
    "    if n_gs == 1:\n",
    "        g = gs[0]\n",
    "        file_name += \"_g_%.1f\" % g\n",
    "    else:\n",
    "        file_name += \"_gs\"\n",
    "    # RNN model\n",
    "    if ML_RNN:\n",
    "        file_name += \"_ML_RNN\"\n",
    "    if not (nonlinearity == 'tanh' or nonlinearity == None):\n",
    "        file_name += \"_%s\" % nonlinearity\n",
    "    if not (readout_nonlinearity == 'tanh' or readout_nonlinearity == None):\n",
    "        file_name += \"_%s\" % readout_nonlinearity\n",
    "    # Optimizer\n",
    "    if optimizer != 'sgd':\n",
    "        file_name += '_' + optimizer\n",
    "    # What is trained\n",
    "    file_name += \"_train\"\n",
    "    if train_wi:\n",
    "        file_name += \"_wi\"\n",
    "    if train_wrec:\n",
    "        file_name += \"_wrec\"\n",
    "    if train_wo:\n",
    "        file_name += \"_wo\"\n",
    "    if train_brec:\n",
    "        file_name += \"_brec\"\n",
    "    if same_connectivity:\n",
    "        file_name += \"_same_conn\"\n",
    "    if orthogonalize_wio:\n",
    "        file_name += \"_ortho_wio\"\n",
    "    if noise_std != 0:\n",
    "        file_name += \"_noise_%.1f\"%noise_std\n",
    "    # Network parameters\n",
    "    file_name += \"_N_%d\"%dim_rec\n",
    "    file_name += \"_lr0_%.2f\" % lr0\n",
    "    file_name = \"\".join(file_name.split('.'))\n",
    "    print(\"file_name:\\n\", file_name)\n",
    "    # Data file for saving\n",
    "    data_file_name = file_name + \".pkl\"\n",
    "    data_file = os.path.join(data_dir, data_file_name)\n",
    "    print(\"data_file:\\n\", data_file)\n",
    "\n",
    "    for k in range(n_samples):\n",
    "        print(\"Sample\", k)\n",
    "        time_t = 0\n",
    "        time_sv = 0\n",
    "        time_r = 0\n",
    "        time_ls = 0\n",
    "        for i, g in enumerate(gs):\n",
    "            print(\"   \", i, g)\n",
    "            \n",
    "            if (not same_connectivity) or i == 0:\n",
    "                # Connectivity\n",
    "                # Initial internal connectivity\n",
    "                wrec_0 = np.random.normal(0, 1 / np.sqrt(dim_rec), (dim_rec, dim_rec))\n",
    "                # Input and output vectors\n",
    "                wio = np.random.normal(0, 1, (dim_rec, dim_in + dim_out))\n",
    "                if orthogonalize_wio:\n",
    "                    wio = np.linalg.qr(wio)[0]\n",
    "                else:\n",
    "                    wio /= np.linalg.norm(wio, axis=0)[None, :]\n",
    "                # Make sure that the vecotrs are still normalized\n",
    "                assert np.allclose(np.linalg.norm(wio, axis=0), 1), \"Normalization gone wrong!\"\n",
    "                # Change normalization to the proper one\n",
    "                wio *= np.sqrt(dim_rec)\n",
    "                wi_init = wio[:, :dim_in].T.copy()\n",
    "                wo_init = wio[:, dim_in:].copy() / dim_rec\n",
    "                del wio\n",
    "\n",
    "            wrec_init = g * wrec_0\n",
    "\n",
    "            # Network\n",
    "            net = RNN(dims, noise_std, dt, \n",
    "                      g=g, wi_init=wi_init, wo_init=wo_init, wrec_init=wrec_init,\n",
    "                      train_wi=train_wi, train_wrec=train_wrec, train_wo=train_wo, train_brec=train_brec,\n",
    "                      nonlinearity=nonlinearity, readout_nonlinearity=readout_nonlinearity, \n",
    "                      ML_RNN=ML_RNN,\n",
    "                     )\n",
    "\n",
    "            # Train\n",
    "            time0_t = time.time()\n",
    "            res = train(net, task, n_epochs, batch_size, lr, cuda=use_cuda, rec_step=rec_step, optimizer=optimizer, verbose=False)\n",
    "            losses, grad_norms, weights_init, weights_last, weights_train, _, _ = res\n",
    "            # Weights\n",
    "            wi_init, wrec_init, wo_init, brec_init = weights_init\n",
    "            wi_last, wrec_last, wo_last, brec_last = weights_last\n",
    "            dwrec_last = wrec_last - wrec_init\n",
    "            wrecs = weights_train[\"wrec\"]\n",
    "            time_t += time.time() - time0_t\n",
    "\n",
    "            # Compute SVs\n",
    "            time0_sv = time.time()\n",
    "            sv_dw = np.linalg.svd(wrecs - wrec_init, compute_uv=False)\n",
    "            del wrecs\n",
    "            time_sv += time.time() - time0_sv\n",
    "\n",
    "            # Reconstruct connectivty with only the largest rank\n",
    "            time0_r = time.time()\n",
    "            u_last, s_last, vT_last = np.linalg.svd(dwrec_last)\n",
    "            # Variance explained\n",
    "            cum_var_rr = np.r_[0, (s_last[:n_ranks - 1]**2).cumsum()]\n",
    "            var_expl = cum_var_rr / (s_last**2).sum()\n",
    "            # Simulate for truncated dwrec\n",
    "            loss_rr_i = np.zeros((n_ranks))\n",
    "            norm_diff_rr_i = np.zeros((n_ranks))\n",
    "            for j, rank in enumerate(ranks):\n",
    "                if rank == 0:\n",
    "                    dw_rr = 0\n",
    "                else:\n",
    "                    dw_rr = (u_last[:, :rank] * s_last[None, :rank]) @ vT_last[:rank]\n",
    "                w_rr = wrec_init + dw_rr\n",
    "\n",
    "                # Run network\n",
    "                net_test = RNN(dims, noise_std, dt, \n",
    "                               g=None, wi_init=wi_last, wo_init=wo_last, wrec_init=w_rr, brec_init=brec_last,\n",
    "                               nonlinearity=nonlinearity, readout_nonlinearity=readout_nonlinearity, \n",
    "                               ML_RNN=ML_RNN,\n",
    "                              )\n",
    "                res_test = run_net(net_test, task, batch_size=batch_size_test)\n",
    "                u, y, mask, z, loss = res_test\n",
    "\n",
    "                # Save\n",
    "                loss_rr_i[j] = loss\n",
    "                norm_diff_rr_i[j] = np.linalg.norm(dw_rr - dwrec_last)\n",
    "            time_r += time.time() - time0_r\n",
    "\n",
    "            ### Loss for shuffled network\n",
    "            time0_ls = time.time()\n",
    "            # Shuffle is in-place!  -> copy!\n",
    "            wrec_init_shuff = wrec_init.copy()\n",
    "            # Shuffle needs reshape\n",
    "            wrec_init_shuff = wrec_init_shuff.reshape((dim_rec**2,))\n",
    "            np.random.shuffle(wrec_init_shuff)\n",
    "            wrec_init_shuff = wrec_init_shuff.reshape((dim_rec, dim_rec))\n",
    "            wrec_shuff = wrec_init_shuff + dwrec_last\n",
    "            # Run network\n",
    "            net_shuff = RNN(dims, noise_std, dt, \n",
    "                            g=None, wi_init=wi_last, wo_init=wo_last, wrec_init=wrec_shuff, brec_init=brec_last,\n",
    "                            nonlinearity=nonlinearity, readout_nonlinearity=readout_nonlinearity, \n",
    "                            ML_RNN=ML_RNN,\n",
    "                           )\n",
    "            res_shuff = run_net(net_shuff, task, batch_size=batch_size_test)\n",
    "            _, _, _, _, loss_shuff = res_shuff\n",
    "            time_ls += time.time() - time0_ls\n",
    "\n",
    "            # Save\n",
    "            wi_init_all[k, i] = wi_init\n",
    "            wrec_init_all[k, i] = wrec_init\n",
    "            wo_init_all[k, i] = wo_init\n",
    "            brec_init_all[k, i] = brec_init\n",
    "            wi_last_all[k, i] = wi_last\n",
    "            wrec_last_all[k, i] = wrec_last\n",
    "            wo_last_all[k, i] = wo_last\n",
    "            brec_last_all[k, i] = brec_last\n",
    "            if train_wi:\n",
    "                wis_all[k, i] = weights_train[\"wi\"]\n",
    "            if train_wo:\n",
    "                wos_all[k, i] = weights_train[\"wo\"]\n",
    "            if train_brec:\n",
    "                brecs_all[k, i] = weights_train[\"brec\"]\n",
    "            losses_all[k, i] = losses\n",
    "            grad_norms_all[k, i] = grad_norms\n",
    "            sv_dw_all[k, i] = sv_dw\n",
    "            loss_rr_all[k, i] = loss_rr_i\n",
    "            norm_diff_rr_all[k, i] = norm_diff_rr_i\n",
    "            var_expl_all[k, i] = var_expl\n",
    "            loss_shuff_all[k, i] = loss_shuff\n",
    "\n",
    "        print(\"Learning took %.1f sec.\" % (time_t))\n",
    "        print(\"SV evaluation took %.1f sec\" % (time_sv))\n",
    "        print(\"Computing reconstruction loss took %.1f sec\" % (time_r))\n",
    "        print(\"Computing loss after shuffle took %.1f sec\" % (time_ls))\n",
    "        \n",
    "    # Compute EVs and SVs at the end of training\n",
    "    time0_es = time.time()\n",
    "    ev_all[0] = np.linalg.eigvals(wrec_init_all)\n",
    "    ev_all[1] = np.linalg.eigvals(wrec_last_all)\n",
    "    ev_all[2] = np.linalg.eigvals(wrec_last_all - wrec_init_all)\n",
    "    sv_all[0] = np.linalg.svd(wrec_init_all, compute_uv=False)\n",
    "    sv_all[1] = np.linalg.svd(wrec_last_all, compute_uv=False)\n",
    "    sv_all[2] = np.linalg.svd(wrec_last_all - wrec_init_all, compute_uv=False)\n",
    "    time_es = time.time() - time0_es\n",
    "    print(\"Computing EVs&SVs for all samples took %.1f sec\" % (time_es))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Save data\n",
    "    to_be_dumped = {\n",
    "        # Simulation parameters\n",
    "        \"dims\": dims, \n",
    "        \"dt\": dt, \n",
    "        \"gs\": gs, \n",
    "        \"lr\": lr,\n",
    "        \"noise_std\": noise_std,\n",
    "        \"ML_RNN\": ML_RNN,\n",
    "        \"nonlinearity\": nonlinearity,\n",
    "        \"readout_nonlinearity\": readout_nonlinearity,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"rec_step\": rec_step,\n",
    "        \"epochs\": epochs, \n",
    "        \"rec_epochs\": rec_epochs, \n",
    "        \"ranks\": ranks,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"batch_size_test\": batch_size_test,\n",
    "        \"train_wi\": train_wi,\n",
    "        \"train_wrec\": train_wrec,\n",
    "        \"train_wo\": train_wo,\n",
    "        \"train_brec\": train_brec,\n",
    "        # Task\n",
    "        \"task_params\": task_params,\n",
    "        # Weights\n",
    "        \"wi_init_all\": wi_init_all,\n",
    "        \"wrec_init_all\": wrec_init_all,\n",
    "        \"wo_init_all\": wo_init_all,\n",
    "        \"brec_init_all\": brec_init_all,\n",
    "        \"wi_last_all\": wi_last_all,\n",
    "        \"wrec_last_all\": wrec_last_all,\n",
    "        \"wo_last_all\": wo_last_all,\n",
    "        \"brec_last_all\": brec_last_all,\n",
    "        # Results\n",
    "        \"losses_all\": losses_all, \n",
    "        \"grad_norms_all\": grad_norms_all, \n",
    "        \"sv_dw_all\": sv_dw_all, \n",
    "        \"loss_rr_all\": loss_rr_all,\n",
    "        \"norm_diff_rr_all\": norm_diff_rr_all,\n",
    "        \"var_expl_all\": var_expl_all,\n",
    "        \"loss_shuff_all\": loss_shuff_all,\n",
    "        \"ev_all\": ev_all,\n",
    "        \"sv_all\": sv_all,\n",
    "        # Computation time\n",
    "        \"time_t\": time_t,\n",
    "        \"time_sv\": time_sv,\n",
    "        \"time_r\": time_r,\n",
    "        \"time_ls\": time_ls,\n",
    "        \"time_es\": time_es,\n",
    "    }\n",
    "    \n",
    "    if train_wi:\n",
    "        to_be_dumped[\"wis_all\"] =  wis_all\n",
    "    if train_wo:\n",
    "        to_be_dumped[\"wos_all\"] =  wos_all\n",
    "    if train_brec:\n",
    "        to_be_dumped[\"brecs_all\"] =  brecs_all\n",
    "        \n",
    "#     with open(data_file, 'wb') as handle:\n",
    "#         pickle.dump(to_be_dumped, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Saved data to \" + data_file + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:\n",
      " flipflop_dim_recs_g_09_adam_train_wi_wrec_wo_N_32_lr0_005\n",
      "data_file:\n",
      " ..\\..\\data\\neurips_2020\\flipflop_dim_recs_g_09_adam_train_wi_wrec_wo_N_32_lr0_005.pkl\n",
      "Sample 0\n",
      "    0 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frsch\\code\\Low-rank-notes\\notebooks\\neurips_2020\\modules.py:234: UserWarning: Nominal g and wrec_init disagree: g = 0.90, g_wrec = 0.91\n",
      "  warn(\"Nominal g and wrec_init disagree: g = %.2f, g_wrec = %.2f\" % (g, g_wrec))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flipflop_dim_recs_g_09_adam_train_wi_wrec_wo_N_32_lr0_005 0.0015625 32 99.7297215461731\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning took 99.7 sec.\n",
      "SV evaluation took 0.0 sec\n",
      "Computing reconstruction loss took 5.8 sec\n",
      "Computing loss after shuffle took 0.2 sec\n",
      "Computing EVs&SVs for all samples took 0.0 sec\n",
      "Saved data to ..\\..\\data\\neurips_2020\\flipflop_dim_recs_g_09_adam_train_wi_wrec_wo_N_32_lr0_005.pkl\n",
      "\n",
      "file_name:\n",
      " mante_dim_recs_g_09_adam_train_wi_wrec_wo_N_32_lr0_005\n",
      "data_file:\n",
      " ..\\..\\data\\neurips_2020\\mante_dim_recs_g_09_adam_train_wi_wrec_wo_N_32_lr0_005.pkl\n",
      "Sample 0\n",
      "    0 0.9\n"
     ]
    }
   ],
   "source": [
    "for dim_rec in dim_recs:\n",
    "    # Flipflop\n",
    "    idx_task = 0\n",
    "    file_name_prefix = tasks_file_name_prefix[idx_task]\n",
    "    n_epochs = tasks_n_epochs[idx_task]\n",
    "    gs = tasks_gs[idx_task]\n",
    "    # Network parameters\n",
    "    dim_in = 2\n",
    "    dim_out = dim_in\n",
    "    dims = [dim_in, dim_rec, dim_out]\n",
    "    # Join\n",
    "    flipflop_params = {\n",
    "        \"t_max\": 50,\n",
    "        \"fixation_duration\": 1,\n",
    "        \"stimulus_duration\": 1,\n",
    "        \"decision_delay_duration\": 5,\n",
    "        \"stim_delay_duration_min\": 5,\n",
    "        \"stim_delay_duration_max\": 25,\n",
    "        \"input_amp\": 1,\n",
    "        \"target_amp\": 0.5,\n",
    "        \"fixate\": False,}\n",
    "    flipflop_specs = (file_name_prefix, n_epochs, gs, dims, flipflop_params, flipflop)\n",
    "\n",
    "    # Mante\n",
    "    idx_task = 1\n",
    "    file_name_prefix = tasks_file_name_prefix[idx_task]\n",
    "    n_epochs = tasks_n_epochs[idx_task]\n",
    "    gs = tasks_gs[idx_task]\n",
    "    # Network parameters\n",
    "    dim_in = 2 * 2\n",
    "    dim_out = 1\n",
    "    dims = [dim_in, dim_rec, dim_out]\n",
    "    # Join\n",
    "    mante_params = {\n",
    "        \"choices\": np.arange(dim_in//2),\n",
    "        \"fixation_duration\":  3,\n",
    "        \"stimulus_duration\":  20,\n",
    "        \"delay_duration\":  5,\n",
    "        \"decision_duration\":  20,\n",
    "        \"input_amp\":  1.,\n",
    "        \"rel_input_std\":  0.05,\n",
    "        \"coherences\":  np.array([-8, -4, -2, -1, 1, 2, 4, 8]) / 8.,\n",
    "        \"context_amp\":  1.,\n",
    "        \"target_amp\":  0.5,\n",
    "        \"fixate\": True,}\n",
    "    mante_specs = (file_name_prefix, n_epochs, gs, dims, mante_params, mante)\n",
    "\n",
    "    # Romo\n",
    "    idx_task = 2\n",
    "    file_name_prefix = tasks_file_name_prefix[idx_task]\n",
    "    n_epochs = tasks_n_epochs[idx_task]\n",
    "    gs = tasks_gs[idx_task]\n",
    "    # Network parameters\n",
    "    dim_in = 1\n",
    "    dim_out = 2\n",
    "    dims = [dim_in, dim_rec, dim_out]\n",
    "    # Join\n",
    "    romo_params = {\n",
    "        \"fixation_duration\": 3,\n",
    "        \"stimulus_duration\": 1,\n",
    "        \"decision_delay_duration\": 5,\n",
    "        \"decision_duration\": 10,\n",
    "        \"stim_delay_duration_min\": 2,\n",
    "        \"stim_delay_duration_max\": 8,\n",
    "        \"input_amp_min\": 0.5,\n",
    "        \"input_amp_max\": 1.5,\n",
    "        \"min_input_diff\": 0.2,\n",
    "        \"target_amp\": 0.5,\n",
    "        \"fixate\": True}\n",
    "    romo_specs = (file_name_prefix, n_epochs, gs, dims, romo_params, romo)\n",
    "\n",
    "    \n",
    "    tasks_specs = [flipflop_specs, mante_specs, romo_specs]\n",
    "    for task_specs in tasks_specs:\n",
    "        run_training(task_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
